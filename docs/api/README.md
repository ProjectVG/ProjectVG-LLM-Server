# LLM Server API ë¬¸ì„œ

ì´ ë¬¸ì„œëŠ” LLM Serverì˜ ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ ìƒì„¸í•œ ëª…ì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ API ê°œìš”

- **Base URL**: `http://localhost:5601`
- **API Version**: v1
- **Content-Type**: `application/json`
- **ë¬¸ì„œ**: http://localhost:5601/docs (FastAPI ìë™ ìƒì„±)

## ğŸ”— ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡

### ì±„íŒ… API
- **POST /api/v1/chat** - AIì™€ì˜ ì±„íŒ… ê¸°ëŠ¥

### ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ API
- **GET /api/v1/system/info** - ì „ì²´ ì‹œìŠ¤í…œ ì •ë³´
- **GET /api/v1/system/status** - í—¬ìŠ¤ì²´í¬
- **GET /api/v1/system/cpu** - CPU ì •ë³´
- **GET /api/v1/system/memory** - ë©”ëª¨ë¦¬ ì •ë³´
- **GET /api/v1/system/disk** - ë””ìŠ¤í¬ ì •ë³´

### ê¸°ë³¸ API
- **GET /** - ì„œë²„ ìƒíƒœ í™•ì¸

---

## ğŸ¤– ì±„íŒ… API

### POST /api/v1/chat

AIì™€ì˜ ì±„íŒ…ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.

#### Request Body

```json
{
  "session_id": "string",
  "system_message": "string",
  "user_message": "string",
  "role": "string",
  "instructions": "string",
  "conversation_history": ["string"],
  "memory_context": ["string"],
  "max_tokens": 1000,
  "temperature": 0.7,
  "model": "gpt-4o-mini",
  "openai_api_key": "string",
  "free_mode": false
}
```

#### í•„ë“œ ìƒì„¸ ì„¤ëª…

| í•„ë“œ | íƒ€ì… | í•„ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|------|------|--------|------|
| `session_id` | string | âŒ | "" | ì„¸ì…˜ ID (ë¡œê¹… ë° ì¶”ì ìš©) |
| `system_message` | string | âŒ | "" | ì¶”ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ |
| `user_message` | string | âœ… | - | ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ |
| `role` | string | âŒ | "" | AI ì—­í•  ì„¤ì • (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨) |
| `instructions` | string | âŒ | "" | ì¶”ê°€ ì§€ì‹œì‚¬í•­ |
| `conversation_history` | string[] | âŒ | [] | ìµœê·¼ ëŒ€í™” ë‚´ì—­ |
| `memory_context` | string[] | âŒ | [] | ì¥ê¸° ê¸°ì–µ Context |
| `max_tokens` | int | âŒ | 1000 | ìµœëŒ€ í† í° ìˆ˜ (0ë³´ë‹¤ ì»¤ì•¼ í•¨) |
| `temperature` | float | âŒ | 0.7 | ìƒì„± ì˜¨ë„ (0-2 ì‚¬ì´) |
| `model` | string | âŒ | "gpt-4o-mini" | ì‚¬ìš©í•  OpenAI ëª¨ë¸ |
| `openai_api_key` | string | âŒ | "" | ì‚¬ìš©í•  OpenAI API Key |
| `free_mode` | bool | âŒ | false | Free ëª¨ë“œ (API Key ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ Key ì‚¬ìš©) |

#### conversation_history í•„ë“œ í˜•ì‹

conversation_history ë°°ì—´ì˜ ê° í•­ëª©ì€ `"role:content"` í˜•íƒœì˜ ë¬¸ìì—´ì…ë‹ˆë‹¤.

- `role`: "user" ë˜ëŠ” "assistant"
- `content`: ì‹¤ì œ ëŒ€í™” ë‚´ìš©

**ì˜ˆì‹œ:**
```json
[
  "user:ì•ˆë…•í•˜ì„¸ìš”",
  "assistant:ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
  "user:íŒŒì´ì¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
]
```

#### API Key ì‚¬ìš© ë°©ì‹

1. **ì¼ë°˜ ëª¨ë“œ** (`free_mode: false`):
   - `openai_api_key`ê°€ ì œê³µë˜ì–´ì•¼ í•¨
   - API Keyê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ

2. **Free ëª¨ë“œ** (`free_mode: true`):
   - `openai_api_key`ê°€ ì œê³µë˜ë©´ ìš°ì„  ì‚¬ìš©
   - API Keyê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ Key ì‚¬ìš©
   - ì‚¬ìš©ì ê´€ë¦¬ ë° ì‚¬ìš©ëŸ‰ ì¶”ì  ê°€ëŠ¥

#### Response

```json
{
  "session_id": "string",
  "response_text": "string",
  "model": "string",
  "input_tokens": 0,
  "output_tokens": 0,
  "total_tokens_used": 0,
  "output_format": "string",
  "created_at": "2024-01-01T00:00:00",
  "temperature": 0.0,
  "instructions": "string",
  "response_time": 0.0,
  "success": true,
  "error_message": null,
  "api_key_source": "user_provided"
}
```

#### Response í•„ë“œ ì„¤ëª…

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `session_id` | string | ì„¸ì…˜ ID |
| `response_text` | string | AI ì‘ë‹µ í…ìŠ¤íŠ¸ |
| `model` | string | ì‚¬ìš©ëœ OpenAI ëª¨ë¸ëª… |
| `input_tokens` | int | ì…ë ¥ í† í° ìˆ˜ |
| `output_tokens` | int | ì¶œë ¥ í† í° ìˆ˜ |
| `total_tokens_used` | int | ì´ í† í° ìˆ˜ |
| `output_format` | string | ì¶œë ¥ í˜•ì‹ |
| `created_at` | string | ì‘ë‹µ ìƒì„± ì‹œê°„ (ISO 8601) |
| `temperature` | float | ì‚¬ìš©ëœ temperature ê°’ |
| `instructions` | string | ì „ë‹¬ëœ ì§€ì‹œì‚¬í•­ |
| `response_time` | float | ì‘ë‹µ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ) |
| `success` | bool | ì„±ê³µ ì—¬ë¶€ |
| `error_message` | string | ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ) |
| `api_key_source` | string | ì‚¬ìš©ëœ API Key ì†ŒìŠ¤ ("user_provided" ë˜ëŠ” "default") |

#### HTTP ìƒíƒœ ì½”ë“œ

- `200 OK`: ì„±ê³µì ì¸ ì‘ë‹µ
- `400 Bad Request`: ìš”ì²­ ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜
- `422 Unprocessable Entity`: ìš”ì²­ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜
- `500 Internal Server Error`: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
- `503 Service Unavailable`: AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜

#### ì‚¬ìš© ì˜ˆì‹œ

**ê¸°ë³¸ ì‚¬ìš©:**
```python
import requests

response = requests.post("http://localhost:5601/api/v1/chat", json={
    "session_id": "session_123",
    "user_message": "íŒŒì´ì¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
    "role": "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ìœ ë¨¸ëŸ¬ìŠ¤í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
    "max_tokens": 1000,
    "temperature": 0.7
})

result = response.json()
print(result['response_text'])
```

**Free ëª¨ë“œ ì‚¬ìš©:**
```python
response = requests.post("http://localhost:5601/api/v1/chat", json={
    "session_id": "session_123",
    "user_message": "íŒŒì´ì¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
    "openai_api_key": "sk-your-api-key",
    "free_mode": True,
    "conversation_history": [
        "user:ì•ˆë…•í•˜ì„¸ìš”",
        "assistant:ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    ]
})

result = response.json()
print(f"ì‘ë‹µ: {result['response_text']}")
print(f"API Key ì†ŒìŠ¤: {result['api_key_source']}")
```

---

## ğŸ“Š ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ API

### GET /api/v1/system/info

ì „ì²´ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

#### Response

```json
{
  "timestamp": "2024-01-01T00:00:00",
  "system": {
    "platform": "Windows",
    "platform_version": "10.0.26100",
    "architecture": "AMD64",
    "processor": "Intel64 Family 6",
    "hostname": "DESKTOP-XXXXX",
    "python_version": "3.11.0"
  },
  "cpu": {
    "usage_percent": 15.2,
    "count": 8,
    "frequency_mhz": 2400.0,
    "frequency_max_mhz": 3200.0,
    "load_average": [0.5, 0.3, 0.2]
  },
  "memory": {
    "total_gb": 16.0,
    "available_gb": 8.0,
    "used_gb": 8.0,
    "usage_percent": 50.0,
    "swap_total_gb": 2.0,
    "swap_used_gb": 0.1,
    "swap_usage_percent": 5.0
  },
  "disk": {
    "total_gb": 500.0,
    "used_gb": 200.0,
    "free_gb": 300.0,
    "usage_percent": 40.0,
    "read_bytes": 1024000,
    "write_bytes": 512000,
    "read_count": 100,
    "write_count": 50
  },
  "network": {
    "bytes_sent": 1000000,
    "bytes_recv": 2000000,
    "packets_sent": 1000,
    "packets_recv": 2000,
    "active_connections": 150
  },
  "process": {
    "pid": 1234,
    "name": "python.exe",
    "cpu_percent": 2.5,
    "memory_mb": 128.5,
    "memory_percent": 1.2,
    "num_threads": 8,
    "create_time": "2024-01-01T00:00:00"
  },
  "docker": {
    "is_docker": false,
    "container_id": null,
    "image": null
  }
}
```

### GET /api/v1/system/status

ê°„ë‹¨í•œ ì‹œìŠ¤í…œ ìƒíƒœ(í—¬ìŠ¤ì²´í¬ìš©)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

#### Response

```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T00:00:00",
  "cpu_usage": 15.2,
  "memory_usage": 35.0,
  "memory_available_gb": 5.2
}
```

### GET /api/v1/system/cpu

CPU ì •ë³´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

#### Response

```json
{
  "timestamp": "2024-01-01T00:00:00",
  "cpu": {
    "usage_percent": 15.2,
    "count": 8,
    "frequency_mhz": 2400.0,
    "frequency_max_mhz": 3200.0,
    "load_average": [0.5, 0.3, 0.2]
  }
}
```

### GET /api/v1/system/memory

ë©”ëª¨ë¦¬ ì •ë³´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

#### Response

```json
{
  "timestamp": "2024-01-01T00:00:00",
  "memory": {
    "total_gb": 16.0,
    "available_gb": 8.0,
    "used_gb": 8.0,
    "usage_percent": 50.0,
    "swap_total_gb": 2.0,
    "swap_used_gb": 0.1,
    "swap_usage_percent": 5.0
  }
}
```

### GET /api/v1/system/disk

ë””ìŠ¤í¬ ì •ë³´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

#### Response

```json
{
  "timestamp": "2024-01-01T00:00:00",
  "disk": {
    "total_gb": 500.0,
    "used_gb": 200.0,
    "free_gb": 300.0,
    "usage_percent": 40.0,
    "read_bytes": 1024000,
    "write_bytes": 512000,
    "read_count": 100,
    "write_count": 50
  }
}
```

---

## âš ï¸ ì—ëŸ¬ ì²˜ë¦¬

APIëŠ” ì²´ê³„ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤:

### ì˜ˆì™¸ íƒ€ì…

1. **ValidationException** (400 Bad Request)
   - ìš”ì²­ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨
   - í•„ìˆ˜ í•„ë“œ ëˆ„ë½, ì˜ëª»ëœ ê°’ í˜•ì‹ ë“±

2. **ConfigurationException** (500 Internal Server Error)
   - ì‹œìŠ¤í…œ ì„¤ì • ì˜¤ë¥˜
   - API í‚¤ ëˆ„ë½, í™˜ê²½ ë³€ìˆ˜ ì˜¤ë¥˜ ë“±

3. **ChatServiceException** (503 Service Unavailable)
   - ì±„íŒ… ì„œë¹„ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜
   - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì˜¤ë¥˜

4. **OpenAIClientException** (503 Service Unavailable)
   - OpenAI API ì—°ê²° ì˜¤ë¥˜
   - API í˜¸ì¶œ ì‹¤íŒ¨, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“±

### ì—ëŸ¬ ì‘ë‹µ í˜•ì‹

ëª¨ë“  ì—ëŸ¬ëŠ” ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µë©ë‹ˆë‹¤:

```json
{
  "session_id": "string",
  "response_text": "",
  "model": "",
  "input_tokens": 0,
  "output_tokens": 0,
  "total_tokens_used": 0,
  "output_format": "",
  "created_at": "2024-01-01T00:00:00",
  "temperature": null,
  "instructions": null,
  "response_time": 0.0,
  "success": false,
  "error_message": "ì˜¤ë¥˜ ë©”ì‹œì§€",
  "api_key_source": null
}
```

### ê²€ì¦ ê·œì¹™

- `user_message`: í•„ìˆ˜ í•„ë“œ, ë¹ˆ ë¬¸ìì—´ ë¶ˆê°€
- `max_tokens`: 0ë³´ë‹¤ ì»¤ì•¼ í•¨
- `temperature`: 0ê³¼ 2 ì‚¬ì´ì˜ ê°’ì´ì–´ì•¼ í•¨
- `conversation_history`: ê° í•­ëª©ì€ "role:content" í˜•ì‹ì´ì–´ì•¼ í•¨
- `openai_api_key`: ì¼ë°˜ ëª¨ë“œì—ì„œëŠ” ìœ íš¨í•œ API Key í•„ìš”

---

## ğŸ“ ì£¼ì˜ì‚¬í•­

1. **í† í° ì œí•œ**: OpenAI APIì˜ í† í° ì œí•œì„ ê³ ë ¤í•˜ì—¬ conversation_history ê¸¸ì´ë¥¼ ì ì ˆíˆ ê´€ë¦¬í•˜ì„¸ìš”.
2. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: memory_context ë°°ì—´ì´ ë„ˆë¬´ ê¸¸ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **íˆìŠ¤í† ë¦¬ í˜•ì‹**: conversation_history ë°°ì—´ì˜ ê° í•­ëª©ì€ ë°˜ë“œì‹œ "role:content" í˜•ì‹ì„ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.
4. **ì—ëŸ¬ ì²˜ë¦¬**: ëª¨ë“  API í˜¸ì¶œì€ ì ì ˆí•œ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
5. **API Key ë³´ì•ˆ**: API KeyëŠ” ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ê³ , ì‘ë‹µì—ëŠ” ì‹¤ì œ í‚¤ê°’ì´ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- **[API í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ](./test-examples.md)**: ë‹¤ì–‘í•œ ì–¸ì–´ë³„ API ì‚¬ìš© ì˜ˆì‹œ
- **[ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ìƒì„¸](./system-monitoring.md)**: ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ API ìƒì„¸ ê°€ì´ë“œ
- **[ì—ëŸ¬ ì²˜ë¦¬ ê°€ì´ë“œ](./error-handling.md)**: ì—ëŸ¬ ì²˜ë¦¬ ë° ë””ë²„ê¹… ê°€ì´ë“œ

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024ë…„ 12ì›”  
**ì‘ì„±ì**: LLM Server ê°œë°œíŒ€ 